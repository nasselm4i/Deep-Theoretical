{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nasselm4i/Deep-Theoretical/blob/main/SSL_Methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gas4pstFpRE2"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/htdt/self-supervised.git && pip install lightly && pip install wandb\n",
        "%cd self-supervised\n",
        "!pip install wandb --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19gfaox6C54w",
        "outputId": "1e807895-ad11-4e44-a7ea-abdcad58597d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.31)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.22.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7Bmhng4LFKV"
      },
      "source": [
        "# Requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55aNIfEAsn69"
      },
      "source": [
        "BarlowTwin - VICReg - BYOL - SimCLR - SimSiam - Data2Vec - Dino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3Mlneb8kLIkd"
      },
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "\n",
        "from lightly.data import LightlyDataset\n",
        "from lightly.data.multi_view_collate import MultiViewCollate\n",
        "from lightly.loss.vicreg_loss import VICRegLoss\n",
        "\n",
        "from lightly.models.modules import BarlowTwinsProjectionHead\n",
        "from lightly.transforms.vicreg_transform import VICRegTransform\n",
        "\n",
        "from lightly.loss import BarlowTwinsLoss\n",
        "from lightly.transforms.simclr_transform import SimCLRTransform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSGbmCZss1QZ"
      },
      "source": [
        "Whitening SSL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zjqHQzHfs8Wl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "98a64119-b375-46f8-8fd4-44809c4e5865"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from tqdm import trange, tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import MultiStepLR, CosineAnnealingWarmRestarts\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "from cfg import get_cfg\n",
        "from datasets import get_ds\n",
        "from methods import get_method\n",
        "\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZImxrqBnuOqa"
      },
      "source": [
        "# BarlowTwin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "\n",
        "from lightly.data import LightlyDataset\n",
        "from lightly.data.multi_view_collate import MultiViewCollate\n",
        "from lightly.loss import BarlowTwinsLoss\n",
        "from lightly.models.modules import BarlowTwinsProjectionHead\n",
        "from lightly.transforms.simclr_transform import SimCLRTransform\n",
        "from sklearn.neighbors import KernelDensity\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "\n",
        "wandb.init(\n",
        "    project=\"BarlowTwin-v0-test\",\n",
        "    config={\n",
        "        \"max_epochs\": 10,\n",
        "        \"batch_size\": 256,\n",
        "        \"lr\": 0.06\n",
        "    })\n",
        "\n",
        "config = wandb.config\n",
        "\n",
        "\n",
        "# def compute_singular_values_2(model, dataloader):\n",
        "# \"\"\"from the dataloader and model directly \"\"\"\n",
        "#     device = next(model.parameters()).device\n",
        "#     singular_values = []\n",
        "#     with torch.no_grad():\n",
        "#         for inputs, *_ in dataloader:\n",
        "#             x0, x1 = inputs\n",
        "#             x0 = x0.to(device)\n",
        "#             x1 = x1.to(device)\n",
        "#             # Get embeddings for the inputs\n",
        "#             z0 = model(x0)\n",
        "#             z1 = model(x1)\n",
        "#             embeddings = torch.cat([z0, z1], dim=0)\n",
        "#             # Compute cross-correlation matrix\n",
        "#             z = embeddings.detach()\n",
        "#             c = torch.matmul(z0.T, z1) / z0.shape[0]\n",
        "#             # Compute singular values\n",
        "#             svd = torch.svd(c)\n",
        "#             singular_values.append(svd.S.cpu().numpy())\n",
        "#     singular_values = np.concatenate(singular_values)\n",
        "#     return singular_values\n",
        "\n",
        "# def mutual_information(x0, z1, bandwidth=0.2, n_samples=10000):\n",
        "#     \"\"\"\n",
        "#     Calculate the mutual information between x0 and z1 using kernel density estimation.\n",
        "\n",
        "#     Args:\n",
        "#     - x0 (np.array): Input data of shape (n_samples, n_features).\n",
        "#     - z1 (np.array): Output data of shape (n_samples, n_features).\n",
        "#     - bandwidth (float): Bandwidth parameter for kernel density estimation.\n",
        "#     - n_samples (int): Number of samples to use for density estimation.\n",
        "\n",
        "#     Returns:\n",
        "#     - mut_info (float): Mutual information between x0 and z1.\n",
        "#     \"\"\"\n",
        "#     with torch.no_grad():\n",
        "#       x0 = x0.cpu().numpy()\n",
        "#       z1 = z1.cpu().numpy()\n",
        "#       n_features = x0.shape[1]\n",
        "#       kde_x0 = KernelDensity(bandwidth=bandwidth).fit(x0)\n",
        "#       kde_z1 = KernelDensity(bandwidth=bandwidth).fit(z1)\n",
        "#       samples_x0 = kde_x0.sample(n_samples)\n",
        "#       samples_z1 = kde_z1.sample(n_samples)\n",
        "#       log_pdf_x0 = kde_x0.score_samples(samples_x0)\n",
        "#       log_pdf_z1 = kde_z1.score_samples(samples_z1)\n",
        "#       log_pdf_joint = kde_x0.score_samples(samples_z1)\n",
        "#       mi = np.mean(log_pdf_x0 + log_pdf_z1 - log_pdf_joint)\n",
        "#       mut_info = mi / np.log(2) / n_features\n",
        "#     return mut_info\n",
        "\n",
        "# def entropy(zX):\n",
        "#     \"\"\"\n",
        "#     Calculate the Shannon entropy of the given embedding.\n",
        "\n",
        "#     Args:\n",
        "#     - zX (np.array): Input embedding of shape (n_samples, n_features).\n",
        "\n",
        "#     Returns:\n",
        "#     - ent (float): Shannon entropy of the embedding.\n",
        "#     \"\"\"\n",
        "#     with torch.no_grad():\n",
        "#       eps = np.finfo(float).eps\n",
        "#       Zx = zX.cpu().numpy()\n",
        "#       n_samples = zX.shape[0]\n",
        "#       _, counts = np.unique(np.argmax(zX, axis=1), return_counts=True)\n",
        "#       probs = counts / n_samples\n",
        "#       ent = - np.sum(probs * np.log2(probs + eps))\n",
        "#       return ent\n",
        "\n",
        "# def entropy(zX):\n",
        "#     eps = 1e-12\n",
        "#     with torch.no_grad():\n",
        "#         zX = torch.softmax(zX, dim=1) #each row sums up to 1\n",
        "#         zX = zX.cpu().numpy() \n",
        "#         n_samples = zX.shape[0]\n",
        "#         _, counts = np.unique(np.argmax(zX, axis=1), return_counts=True)\n",
        "#         probs = counts / n_samples\n",
        "#         ent = - np.sum(probs * np.log2(probs + eps))\n",
        "#     return ent\n",
        "\n",
        "def cross_correlation_matrix(z0, z1):\n",
        "  \"\"\"\n",
        "    Compute the cross-correlation matrix between the embeddings z0 and z1.\n",
        "    \n",
        "    Args:\n",
        "    - z0 (torch.Tensor): The embedding tensor for the first sequence, with shape (seq_len, embedding_dim).\n",
        "    - z1 (torch.Tensor): The embedding tensor for the second sequence, with shape (seq_len, embedding_dim).\n",
        "    \n",
        "    Returns:\n",
        "    - c (np.ndarray): the cross-correlation matrix.\n",
        "    \"\"\"\n",
        "  with torch.no_grad():\n",
        "      z0_centered = z0 - z0.mean(dim=0)\n",
        "      z1_centered = z1 - z1.mean(dim=0)\n",
        "      c = torch.matmul(z0_centered.T, z1_centered) / (z0_centered.shape[0] - 1)\n",
        "      std0 = z0_centered.std(dim=0, unbiased=False)\n",
        "      std1 = z1_centered.std(dim=0, unbiased=False)\n",
        "      c = c / torch.outer(std0, std1)\n",
        "      return c\n",
        "\n",
        "def entropy(zX):\n",
        "    eps = 1e-12\n",
        "    with torch.no_grad():\n",
        "        zX = torch.softmax(zX, dim=1)\n",
        "        ent = torch.sum(-zX * torch.log2(zX + eps), dim=1)\n",
        "        ent = torch.mean(ent)\n",
        "    return ent.item()\n",
        "\n",
        "\n",
        "def compute_singular_values(z0, z1):\n",
        "    \"\"\"\n",
        "    Compute the singular values of the cross-correlation matrix between the embeddings z0 and z1.\n",
        "    \n",
        "    Args:\n",
        "    - z0 (torch.Tensor): The embedding tensor for the first sequence, with shape (seq_len, embedding_dim).\n",
        "    - z1 (torch.Tensor): The embedding tensor for the second sequence, with shape (seq_len, embedding_dim).\n",
        "    \n",
        "    Returns:\n",
        "    - singular_values (np.ndarray): The singular values of the cross-correlation matrix, sorted in descending order.\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "      # Compute cross-correlation matrix\n",
        "      c = cross_correlation_matrix(z0, z1)\n",
        "\n",
        "      # Compute singular values\n",
        "      svd = torch.svd(c)\n",
        "      singular_values = svd.S.cpu().detach().numpy()\n",
        "      return singular_values\n",
        "\n",
        "\n",
        "def compute_average_off_correlation_matrix(z0,z1):\n",
        "  \"\"\"\n",
        "    Compute the average of the off diagonal of the cross-correlation matrix between the embeddings z0 and z1.\n",
        "    \n",
        "    Args:\n",
        "    - z0 (torch.Tensor): The embedding tensor for the first sequence, with shape (seq_len, embedding_dim).\n",
        "    - z1 (torch.Tensor): The embedding tensor for the second sequence, with shape (seq_len, embedding_dim).\n",
        "    \n",
        "    Returns:\n",
        "    - corr (float): The average of the off diagonal of the cross-correlation matrix.\n",
        "    \"\"\"\n",
        "  with torch.no_grad():\n",
        "    c = cross_correlation_matrix(z0, z1)\n",
        "    corr = (c.flatten()[c.shape[0]::c.shape[0]+1].mean().item())\n",
        "    return corr\n",
        "\n",
        "class BarlowTwins(nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.projection_head = BarlowTwinsProjectionHead(512, 2048, 2048)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(x)\n",
        "        return z\n",
        "\n",
        "\n",
        "resnet = torchvision.models.resnet18()\n",
        "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "model = BarlowTwins(backbone)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "cifar10 = torchvision.datasets.CIFAR10(\"datasets/cifar10\", download=True)\n",
        "transform = SimCLRTransform(input_size=32)\n",
        "dataset = LightlyDataset.from_torch_dataset(cifar10, transform=transform)\n",
        "\n",
        "collate_fn = MultiViewCollate()\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=config.batch_size,\n",
        "    collate_fn=collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=8,\n",
        ")\n",
        "\n",
        "criterion = BarlowTwinsLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=config.lr)\n",
        "\n",
        "print(\"Starting Training\")\n",
        "start = time.time()\n",
        "for epoch in tqdm(range(config.max_epochs)):\n",
        "    total_loss = 0\n",
        "    corr = 0\n",
        "    corr_count = 0\n",
        "    for (x0, x1), _, _ in dataloader:\n",
        "        x0 = x0.to(device)\n",
        "        x1 = x1.to(device)\n",
        "        z0 = model(x0)\n",
        "        z1 = model(x1)\n",
        "        loss = criterion(z0, z1)\n",
        "        total_loss += loss.detach()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    avg_corr = compute_average_off_correlation_matrix(z0,z1)\n",
        "    entropy_z0 = entropy(z0)\n",
        "    entropy_z1 = entropy(z1)\n",
        "    # mut_info = mutual_information(x0, z1, bandwidth=0.2, n_samples=10000)\n",
        "    # print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}, avg cross-correlation: {avg_corr}, mutual information: {mut_info} \")\n",
        "    wandb.log({\"avg_loss\": avg_loss, \"avg_corr\": avg_corr, \"entropy_z0\": entropy_z0, \"entropy_z1\": entropy_z1})\n",
        "\n",
        "# time to train \n",
        "end = time.time()\n",
        "train_time = time.strftime(\"%H:%M:%S\", time.gmtime(end - start))\n",
        "print(\"Time for the training :\", train_time)\n",
        "# compute singular values\n",
        "singular_values = compute_singular_values(z0, z1)\n",
        "\n",
        "# plot singular values\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(range(singular_values.size),singular_values, label=f'Singular Values')\n",
        "ax.set_yscale('log')\n",
        "ax.set_xlabel('Singular Value Index')\n",
        "ax.set_ylabel('Singular Value')\n",
        "wandb.log({\"Log Singular Values \": fig})\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), 'BarlowTwinV0.pth')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "erI1VTL39qLG",
        "outputId": "3bf80419-2115-4301-f5b2-68b8de46b6c7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:kw2ixur6) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_corr</td><td>▃▅▁▃▁▆▆▄█▂</td></tr><tr><td>avg_loss</td><td>█▇▅▄▄▃▃▃▂▁</td></tr><tr><td>entropy_z0</td><td>▆▁▄▇██▇▆▇█</td></tr><tr><td>entropy_z1</td><td>▆▁▄▇█▇█▆▇█</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_corr</td><td>-0.00081</td></tr><tr><td>avg_loss</td><td>1309.15906</td></tr><tr><td>entropy_z0</td><td>1.20232</td></tr><tr><td>entropy_z1</td><td>1.2014</td></tr><tr><td>epoch</td><td>9</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">astral-rain-13</strong> at: <a href='https://wandb.ai/naelm/BarlowTwin-v0-test/runs/kw2ixur6' target=\"_blank\">https://wandb.ai/naelm/BarlowTwin-v0-test/runs/kw2ixur6</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230506_170415-kw2ixur6/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:kw2ixur6). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/self-supervised/wandb/run-20230506_173057-aoujw9v2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/naelm/BarlowTwin-v0-test/runs/aoujw9v2' target=\"_blank\">dandy-wildflower-14</a></strong> to <a href='https://wandb.ai/naelm/BarlowTwin-v0-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/naelm/BarlowTwin-v0-test' target=\"_blank\">https://wandb.ai/naelm/BarlowTwin-v0-test</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/naelm/BarlowTwin-v0-test/runs/aoujw9v2' target=\"_blank\">https://wandb.ai/naelm/BarlowTwin-v0-test/runs/aoujw9v2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [26:48<00:00, 160.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00:26:48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/plotly/matplotlylib/renderer.py:611: UserWarning:\n",
            "\n",
            "I found a path object that I don't think is part of a bar chart. Ignoring.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class BarlowTwins(nn.Module):\n",
        "#     def __init__(self, backbone):\n",
        "#         super().__init__()\n",
        "#         self.backbone = backbone\n",
        "#         self.projection_head = BarlowTwinsProjectionHead(512, 2048, 2048)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.backbone(x).flatten(start_dim=1)\n",
        "#         z = self.projection_head(x)\n",
        "#         return z\n",
        "\n",
        "\n",
        "# resnet = torchvision.models.resnet18()\n",
        "# backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "# model = BarlowTwins(backbone)\n",
        "\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# model.to(device)\n",
        "\n",
        "# cifar10 = torchvision.datasets.CIFAR10(\"datasets/cifar10\", download=True)\n",
        "# transform = SimCLRTransform(input_size=32)\n",
        "# dataset = LightlyDataset.from_torch_dataset(cifar10, transform=transform)\n",
        "\n",
        "# collate_fn = MultiViewCollate()\n",
        "\n",
        "# dataloader = torch.utils.data.DataLoader(\n",
        "#     dataset,\n",
        "#     batch_size=256,\n",
        "#     collate_fn=collate_fn,\n",
        "#     shuffle=True,\n",
        "#     drop_last=True,\n",
        "#     num_workers=8,\n",
        "# )\n",
        "# # classes = dataset.classes\n",
        "# dataset.dataset\n",
        "# for batch_idx, (views, targets, filenames) in enumerate(dataloader):\n",
        "#   # Forward pass\n",
        "#   print(\"input\", views)\n",
        "#   print(\"target\", targets)\n",
        "\n",
        "# # Define your model and optimizer\n",
        "# model = MyModel()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# # Train loop\n",
        "# for epoch in range(10):\n",
        "#     for batch_idx, batch in enumerate(dataloader):\n",
        "#         # Forward pass\n",
        "#         inputs, targets = batch['input'], batch['target']\n",
        "#         outputs = model(inputs)\n",
        "#         loss = compute_loss(outputs, targets)\n",
        "        \n",
        "#         # Backward pass\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "        \n",
        "#         # Print progress\n",
        "#         if batch_idx % 1 == 0:\n",
        "#             print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "#                 epoch, batch_idx * len(inputs), len(dataloader.dataset),\n",
        "#                 100. * batch_idx / len(dataloader), loss.item()))\n",
        "\n"
      ],
      "metadata": {
        "id": "hdB3ePfRKMgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torchvision\n",
        "# from torch.utils.data import DataLoader\n",
        "# from typing import List, Tuple\n",
        "\n",
        "# # define the transforms to use\n",
        "# transform = SimCLRTransform(input_size=32)\n",
        "\n",
        "# # load the CIFAR10 test dataset\n",
        "# cifar10_test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True)\n",
        "\n",
        "# # create a LightlyDataset for the CIFAR10 test dataset with the defined transform\n",
        "# dataset = LightlyDataset.from_torch_dataset(cifar10_test, transform=transform)\n",
        "\n",
        "# # create a DataLoader for the test dataset\n",
        "# collate_fn = MultiViewCollate()\n",
        "# batch_size = 256  # adjust this according to your available memory\n",
        "# num_workers = 8  # adjust this according to your available CPU resources\n",
        "# test_loader = torch.utils.data.DataLoader(\n",
        "#     dataset,\n",
        "#     batch_size=batch_size,\n",
        "#     collate_fn=collate_fn,\n",
        "#     shuffle=False,\n",
        "#     num_workers=num_workers,\n",
        "#     drop_last=False\n",
        "# )\n",
        "\n",
        "# # load your trained Barlow Twin model\n",
        "# checkpoint = torch.load('BarlowTwinV0.pth')\n",
        "\n",
        "# resnet = torchvision.models.resnet18()\n",
        "# backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "# model = BarlowTwins(backbone)\n",
        "# model.load_state_dict(checkpoint)\n",
        "\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# model.to(device)\n",
        "\n",
        "# # set the model to evaluation mode\n",
        "# model.eval()\n",
        "\n",
        "# # define a function to compute the accuracy of the model on the test dataset\n",
        "# # def test(model: torch.nn.Module, test_loader: torch.utils.data.DataLoader) -> float:\n",
        "# #     num_correct = 0\n",
        "# #     num_total = 0\n",
        "# #     with torch.no_grad():\n",
        "# #         for views, labels, filenames in test_loader:\n",
        "# #             # move the views and labels to the device used for training the model\n",
        "# #             views = [view.to(device) for view in views]\n",
        "# #             labels = labels.to(device)\n",
        "\n",
        "# #             # compute the forward pass of the model\n",
        "# #             projections = model(views)\n",
        "\n",
        "# #             # compute the cosine similarity between the projections of the views\n",
        "# #             sim_matrix = torch.matmul(projections, projections.t())\n",
        "# #             sim_matrix = sim_matrix - torch.diag(sim_matrix.diag())\n",
        "# #             sim_matrix = sim_matrix / torch.norm(sim_matrix, dim=1, keepdim=True)\n",
        "\n",
        "# #             # predict the label by selecting the view with the highest average cosine similarity\n",
        "# #             pred = sim_matrix.mean(1).argmax().item()\n",
        "\n",
        "# #             # compute the number of correctly classified images\n",
        "# #             num_correct += int(pred == labels.item())\n",
        "\n",
        "# #             # update the total number of images\n",
        "# #             num_total += 1\n",
        "\n",
        "# #     # return the accuracy of the model on the test dataset\n",
        "# #     return num_correct / num_total\n",
        "\n",
        "# def test(model: torch.nn.Module, test_loader: torch.utils.data.DataLoader) -> float:\n",
        "#     num_correct = 0\n",
        "#     num_total = 0\n",
        "#     with torch.no_grad():\n",
        "#         for views, labels, filenames in test_loader:\n",
        "#             # move the views and labels to the device used for training the model\n",
        "#             views = [view.to(device) for view in views]\n",
        "#             labels = labels.to(device)\n",
        "\n",
        "#             # compute the forward pass of the model\n",
        "#             projections = model(views)\n",
        "\n",
        "#             # compute the cosine similarity between the projections of the views\n",
        "#             sim_matrix = torch.matmul(projections, projections.t())\n",
        "#             sim_matrix = sim_matrix - torch.diag(sim_matrix.diag())\n",
        "#             sim_matrix = sim_matrix / torch.norm(sim_matrix, dim=1, keepdim=True)\n",
        "\n",
        "#             # predict the label by selecting the view with the highest average cosine similarity\n",
        "#             pred = sim_matrix.mean(1).argmax(dim=0)  # compute predicted labels for the batch\n",
        "\n",
        "#             # compute the number of correctly classified images\n",
        "#             num_correct += (pred == labels).sum().item()\n",
        "\n",
        "#             # update the total number of images\n",
        "#             num_total += len(labels)\n",
        "\n",
        "#     # return the accuracy of the model on the test dataset\n",
        "#     return num_correct / num_total\n",
        "\n",
        "# # calculate the accuracy of the model on the test dataset\n",
        "# accuracy = test(model, test_loader)\n",
        "# print(f'Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "id": "LfxKQEvw6W9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('BarlowTwinV0.pth')\n",
        "print(model.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOhumceaRhY6",
        "outputId": "784ddc65-bdab-4376-ee1f-f0fed2193137"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['backbone.0.weight', 'backbone.1.weight', 'backbone.1.bias', 'backbone.1.running_mean', 'backbone.1.running_var', 'backbone.1.num_batches_tracked', 'backbone.4.0.conv1.weight', 'backbone.4.0.bn1.weight', 'backbone.4.0.bn1.bias', 'backbone.4.0.bn1.running_mean', 'backbone.4.0.bn1.running_var', 'backbone.4.0.bn1.num_batches_tracked', 'backbone.4.0.conv2.weight', 'backbone.4.0.bn2.weight', 'backbone.4.0.bn2.bias', 'backbone.4.0.bn2.running_mean', 'backbone.4.0.bn2.running_var', 'backbone.4.0.bn2.num_batches_tracked', 'backbone.4.1.conv1.weight', 'backbone.4.1.bn1.weight', 'backbone.4.1.bn1.bias', 'backbone.4.1.bn1.running_mean', 'backbone.4.1.bn1.running_var', 'backbone.4.1.bn1.num_batches_tracked', 'backbone.4.1.conv2.weight', 'backbone.4.1.bn2.weight', 'backbone.4.1.bn2.bias', 'backbone.4.1.bn2.running_mean', 'backbone.4.1.bn2.running_var', 'backbone.4.1.bn2.num_batches_tracked', 'backbone.5.0.conv1.weight', 'backbone.5.0.bn1.weight', 'backbone.5.0.bn1.bias', 'backbone.5.0.bn1.running_mean', 'backbone.5.0.bn1.running_var', 'backbone.5.0.bn1.num_batches_tracked', 'backbone.5.0.conv2.weight', 'backbone.5.0.bn2.weight', 'backbone.5.0.bn2.bias', 'backbone.5.0.bn2.running_mean', 'backbone.5.0.bn2.running_var', 'backbone.5.0.bn2.num_batches_tracked', 'backbone.5.0.downsample.0.weight', 'backbone.5.0.downsample.1.weight', 'backbone.5.0.downsample.1.bias', 'backbone.5.0.downsample.1.running_mean', 'backbone.5.0.downsample.1.running_var', 'backbone.5.0.downsample.1.num_batches_tracked', 'backbone.5.1.conv1.weight', 'backbone.5.1.bn1.weight', 'backbone.5.1.bn1.bias', 'backbone.5.1.bn1.running_mean', 'backbone.5.1.bn1.running_var', 'backbone.5.1.bn1.num_batches_tracked', 'backbone.5.1.conv2.weight', 'backbone.5.1.bn2.weight', 'backbone.5.1.bn2.bias', 'backbone.5.1.bn2.running_mean', 'backbone.5.1.bn2.running_var', 'backbone.5.1.bn2.num_batches_tracked', 'backbone.6.0.conv1.weight', 'backbone.6.0.bn1.weight', 'backbone.6.0.bn1.bias', 'backbone.6.0.bn1.running_mean', 'backbone.6.0.bn1.running_var', 'backbone.6.0.bn1.num_batches_tracked', 'backbone.6.0.conv2.weight', 'backbone.6.0.bn2.weight', 'backbone.6.0.bn2.bias', 'backbone.6.0.bn2.running_mean', 'backbone.6.0.bn2.running_var', 'backbone.6.0.bn2.num_batches_tracked', 'backbone.6.0.downsample.0.weight', 'backbone.6.0.downsample.1.weight', 'backbone.6.0.downsample.1.bias', 'backbone.6.0.downsample.1.running_mean', 'backbone.6.0.downsample.1.running_var', 'backbone.6.0.downsample.1.num_batches_tracked', 'backbone.6.1.conv1.weight', 'backbone.6.1.bn1.weight', 'backbone.6.1.bn1.bias', 'backbone.6.1.bn1.running_mean', 'backbone.6.1.bn1.running_var', 'backbone.6.1.bn1.num_batches_tracked', 'backbone.6.1.conv2.weight', 'backbone.6.1.bn2.weight', 'backbone.6.1.bn2.bias', 'backbone.6.1.bn2.running_mean', 'backbone.6.1.bn2.running_var', 'backbone.6.1.bn2.num_batches_tracked', 'backbone.7.0.conv1.weight', 'backbone.7.0.bn1.weight', 'backbone.7.0.bn1.bias', 'backbone.7.0.bn1.running_mean', 'backbone.7.0.bn1.running_var', 'backbone.7.0.bn1.num_batches_tracked', 'backbone.7.0.conv2.weight', 'backbone.7.0.bn2.weight', 'backbone.7.0.bn2.bias', 'backbone.7.0.bn2.running_mean', 'backbone.7.0.bn2.running_var', 'backbone.7.0.bn2.num_batches_tracked', 'backbone.7.0.downsample.0.weight', 'backbone.7.0.downsample.1.weight', 'backbone.7.0.downsample.1.bias', 'backbone.7.0.downsample.1.running_mean', 'backbone.7.0.downsample.1.running_var', 'backbone.7.0.downsample.1.num_batches_tracked', 'backbone.7.1.conv1.weight', 'backbone.7.1.bn1.weight', 'backbone.7.1.bn1.bias', 'backbone.7.1.bn1.running_mean', 'backbone.7.1.bn1.running_var', 'backbone.7.1.bn1.num_batches_tracked', 'backbone.7.1.conv2.weight', 'backbone.7.1.bn2.weight', 'backbone.7.1.bn2.bias', 'backbone.7.1.bn2.running_mean', 'backbone.7.1.bn2.running_var', 'backbone.7.1.bn2.num_batches_tracked', 'projection_head.layers.0.weight', 'projection_head.layers.1.weight', 'projection_head.layers.1.bias', 'projection_head.layers.1.running_mean', 'projection_head.layers.1.running_var', 'projection_head.layers.1.num_batches_tracked', 'projection_head.layers.3.weight', 'projection_head.layers.4.weight', 'projection_head.layers.4.bias', 'projection_head.layers.4.running_mean', 'projection_head.layers.4.running_var', 'projection_head.layers.4.num_batches_tracked', 'projection_head.layers.6.weight', 'projection_head.layers.6.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a linear classifier\n",
        "class LinearClassifier(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(LinearClassifier, self).__init__()\n",
        "        self.fc = nn.Linear(input_size, output_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.fc(x)\n",
        "        return out\n",
        "\n",
        "# initialize the linear classifier\n",
        "linear_classifier = LinearClassifier(input_size=barlow_twins_model.embedding_size, output_size=num_classes)\n",
        "\n",
        "# define the loss function and the optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(linear_classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "# train the linear classifier\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # forward pass\n",
        "        embeddings = barlow_twins_model(images)\n",
        "        outputs = linear_classifier(embeddings)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# evaluate the linear classifier\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        # compute the embeddings using the Barlow Twins model\n",
        "        embeddings = barlow_twins_model(images)\n",
        "        \n",
        "        # compute the outputs using the linear classifier\n",
        "        outputs = linear_classifier(embeddings)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        \n",
        "        # update the accuracy\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "accuracy = 100 * correct / total\n",
        "print('Accuracy: {:.2f}%'.format(accuracy))\n"
      ],
      "metadata": {
        "id": "2AIrUxX8NN6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1U2KmIuuMJ_"
      },
      "source": [
        "# VICReg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5J6b9LnxDH2"
      },
      "source": [
        "- Changing the "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468,
          "referenced_widgets": [
            "688f650350a440a390fa8dcec3b04905",
            "24babb3fa24140ad9810682be73e3faf",
            "fbf93f2532da4fbb97be9d1fa24625f2",
            "fb1b1e5e7bed478fbaf0170be55f2928",
            "bdeeadf648084ae197d5111479d81239",
            "e3f1536fbecb4f818efa5a4bd272fcab",
            "c5116606ca3b42ea97dea84f2bb29a0d",
            "cf503d517c7f46c98966ea2d1746479f",
            "1caf21ab99984e9bb0321d9c240b57d7",
            "7c1ac5a015e043f499fba391cda8b5d7",
            "ad62ad3b64fc473db567f104498d5ad7"
          ]
        },
        "id": "Gpcn65MWuXCD",
        "outputId": "620f727f-d0da-45bc-c8c5-6f774198fd09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to datasets/cifar10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:06<00:00, 25816745.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting datasets/cifar10/cifar-10-python.tar.gz to datasets/cifar10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name            | Type                      | Params\n",
            "--------------------------------------------------------------\n",
            "0 | backbone        | Sequential                | 11.2 M\n",
            "1 | projection_head | BarlowTwinsProjectionHead | 9.4 M \n",
            "2 | criterion       | VICRegLoss                | 0     \n",
            "--------------------------------------------------------------\n",
            "20.6 M    Trainable params\n",
            "0         Non-trainable params\n",
            "20.6 M    Total params\n",
            "82.496    Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "688f650350a440a390fa8dcec3b04905",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.init(\n",
        "    project=\"BarlowTwin-v0-test\",\n",
        "    config={\n",
        "        \"max_epochs\": 10,\n",
        "        \"batch_size\": 256,\n",
        "        \"lr\": 0.06\n",
        "    })\n",
        "\n",
        "config = wandb.config\n",
        "\n",
        "class VICReg(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        resnet = torchvision.models.resnet18()\n",
        "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "        self.projection_head = BarlowTwinsProjectionHead(512, 2048, 2048)\n",
        "        self.criterion = VICRegLoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(x)\n",
        "        return z\n",
        "\n",
        "    def training_step(self, batch, batch_index):\n",
        "        (x0, x1), _, _ = batch\n",
        "        z0 = self.forward(x0)\n",
        "        z1 = self.forward(x1)\n",
        "        loss = self.criterion(z0, z1)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optim = torch.optim.SGD(self.parameters(), lr=0.06)\n",
        "        return optim\n",
        "\n",
        "\n",
        "model = VICReg()\n",
        "\n",
        "cifar10 = torchvision.datasets.CIFAR10(\"datasets/cifar10\", download=True)\n",
        "dataset = LightlyDataset.from_torch_dataset(cifar10, VICRegTransform(input_size=32))\n",
        "# or create a dataset from a folder containing images or videos:\n",
        "# dataset = LightlyDataset(\"path/to/folder\")\n",
        "\n",
        "collate_fn = MultiViewCollate()\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=256,\n",
        "    collate_fn=collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=8,\n",
        ")\n",
        "\n",
        "accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=10, devices=1, accelerator=accelerator)\n",
        "trainer.fit(model=model, train_dataloaders=dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guMoZCaPuGJQ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbezgE5MmPlW"
      },
      "source": [
        "# Whitening Self Supervised Learning (Building in Progress)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{gathered}\n",
        "\\min _\\theta \\mathbb{E}\\left[\\operatorname{dist}\\left(\\mathbf{z}_i, \\mathbf{z}_j\\right)\\right], \\\\\n",
        "\\text { s.t. } \\operatorname{cov}\\left(\\mathbf{z}_i, \\mathbf{z}_i\\right)=\\operatorname{cov}\\left(\\mathbf{z}_j, \\mathbf{z}_j\\right)=I,\n",
        "\\end{gathered}\n",
        "\n",
        "$$\n",
        "\\begin{gathered}\n",
        "\\operatorname{dist}\\left(\\mathbf{z}_i, \\mathbf{z}_j\\right)=\\left\\|\\frac{\\mathbf{z}_i}{\\left\\|\\mathbf{z}_i\\right\\|_2}-\\frac{\\mathbf{z}_j}{\\left\\|\\mathbf{z}_j\\right\\|_2}\\right\\|_2^2 \\\\\n",
        "=2-2 \\frac{\\left\\langle\\mathbf{z}_i, \\mathbf{z}_j\\right\\rangle}{\\left\\|\\mathbf{z}_i\\right\\|_2 \\cdot\\left\\|\\mathbf{z}_j\\right\\|_2}\n",
        "\\end{gathered}\n",
        "$$\n",
        "$$\n",
        "L_{W-M S E}(V)=\\frac{2}{N d(d-1)} \\sum \\operatorname{dist}\\left(\\mathbf{z}_i, \\mathbf{z}_j\\right)\n",
        "$$\n",
        "where the sum is over $\\left(\\mathbf{v}_i, \\mathbf{v}_j\\right) \\in V, \\operatorname{pos}(i, j)=$ true, $\\mathbf{z}=$ $\\operatorname{Whitening}(\\mathbf{v})$, and:\n",
        "$\\operatorname{Whitening}(\\mathbf{v})=W_V\\left(\\mathbf{v}-\\boldsymbol{\\mu}_V\\right)$.\n",
        "$\\boldsymbol{\\mu}_V$ is the mean of the elements in $V: \\boldsymbol{\\mu}_V=$ $\\frac{1}{K} \\sum_k \\mathbf{v}_k$, while the matrix $W_V$ is such that: $W_V^{\\top} W_V=$ $\\Sigma_V^{-1}$, being $\\Sigma_V$ the covariance matrix of $V$ :\n",
        "$$\n",
        "\\Sigma_V=\\frac{1}{K-1} \\sum_k\\left(\\mathbf{v}_k-\\boldsymbol{\\mu}_V\\right)\\left(\\mathbf{v}_k-\\boldsymbol{\\mu}_V\\right)^T\n",
        "$$\n",
        "We provide here the equations for whitening differentiation as reported in (Siarohin et al., 2019). Let $Z$ be the whitened version of the batch $V$, i.e., $Z=W_V\\left(V-\\boldsymbol{\\mu}_V\\right)$. The gradient $\\frac{\\partial L}{\\partial V}$ can be computed by:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial V}=\\frac{2}{K-1} \\frac{\\partial L}{\\partial \\Sigma} V+W_V^T \\frac{\\partial L}{\\partial Z}\n",
        "$$\n",
        "where the partial derivative $\\frac{\\partial L}{\\partial Z}$ is backpropogated, while $\\frac{\\partial L}{\\partial \\Sigma}$ is computed as follows:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial \\Sigma}=-\\frac{1}{2} W_V^T\\left(P \\circ \\frac{\\partial L}{\\partial W_V} W_V^T+\\left(P \\circ \\frac{\\partial L}{\\partial W_V} W_V^T\\right)^T\\right) W_V\n",
        "$$\n",
        "In (10), $\\circ$ is Hadamard product, while $\\frac{\\partial L}{\\partial W_V}$ is:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W_V}=\\frac{\\partial L}{\\partial Z} V^T\n",
        "$$\n",
        "and $P$ is:\n",
        "$$\n",
        "P=\\left(\\begin{array}{cccc}\n",
        "\\frac{1}{2} & 0 & \\cdots & 0 \\\\\n",
        "1 & \\frac{1}{2} & \\ddots & 0 \\\\\n",
        "1 & \\ddots & \\ddots & 0 \\\\\n",
        "1 & \\cdots & 1 & \\frac{1}{2}\n",
        "\\end{array}\\right)\n",
        "$$"
      ],
      "metadata": {
        "id": "xORLsk0E02mO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MJo73DPIDe99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCPhFRsMh1xf"
      },
      "source": [
        "#### W-MSE 4\n",
        "```\n",
        "python -m train --dataset cifar10 --epoch 1000 --lr 3e-3 --num_samples 4 --bs 256 --emb 64 --w_size 128\n",
        "python -m train --dataset cifar100 --epoch 1000 --lr 3e-3 --num_samples 4 --bs 256 --emb 64 --w_size 128\n",
        "python -m train --dataset stl10 --epoch 2000 --lr 2e-3 --num_samples 4 --bs 256 --emb 128 --w_size 256\n",
        "python -m train --dataset tiny_in --epoch 1000 --lr 2e-3 --num_samples 4 --bs 256 --emb 128 --w_size 256\n",
        "```\n",
        "\n",
        "#### W-MSE 2\n",
        "```\n",
        "python -m train --dataset cifar10 --epoch 1000 --lr 3e-3 --emb 64 --w_size 128\n",
        "python -m train --dataset cifar100 --epoch 1000 --lr 3e-3 --emb 64 --w_size 128\n",
        "python -m train --dataset stl10 --epoch 2000 --lr 2e-3 --emb 128 --w_size 256 --w_iter 4\n",
        "python -m train --dataset tiny_in --epoch 1000 --lr 2e-3 --emb 128 --w_size 256 --w_iter 4\n",
        "```\n",
        "\n",
        "#### Contrastive\n",
        "```\n",
        "python -m train --dataset cifar10 --epoch 1000 --lr 3e-3 --emb 64 --method contrastive\n",
        "python -m train --dataset cifar100 --epoch 1000 --lr 3e-3 --emb 64 --method contrastive\n",
        "python -m train --dataset stl10 --epoch 2000 --lr 2e-3 --emb 128 --method contrastive\n",
        "python -m train --dataset tiny_in --epoch 1000 --lr 2e-3 --emb 128 --method contrastive\n",
        "```\n",
        "\n",
        "#### BYOL\n",
        "```\n",
        "python -m train --dataset cifar10 --epoch 1000 --lr 3e-3 --emb 64 --method byol\n",
        "python -m train --dataset cifar100 --epoch 1000 --lr 3e-3 --emb 64 --method byol\n",
        "python -m train --dataset stl10 --epoch 2000 --lr 2e-3 --emb 128 --method byol\n",
        "python -m train --dataset tiny_in --epoch 1000 --lr 2e-3 --emb 128 --method byol\n",
        "```\n",
        "\n",
        "#### ImageNet-100\n",
        "```\n",
        "python -m train --dataset imagenet --epoch 240 --lr 2e-3 --emb 128 --w_size 256 --crop_s0 0.08 --cj0 0.8 --cj1 0.8 --cj2 0.8 --cj3 0.2 --gs_p 0.2\n",
        "python -m train --dataset imagenet --epoch 240 --lr 2e-3 --num_samples 4 --bs 256 --emb 128 --w_size 256 --crop_s0 0.08 --cj0 0.8 --cj1 0.8 --cj2 0.8 --cj3 0.2 --gs_p 0.2\n",
        "```\n",
        "\n",
        "Use `--no_norm` to disable normalization (for Euclidean distance).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Press (2) Existing account \\\\\n",
        "API KEY = 99c1b4fb29042df88f0099033d45baa2f380d34d"
      ],
      "metadata": {
        "id": "JrCZTOzNkOzh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k81IEssh1xg",
        "outputId": "26e1276c-1e78-4f81-8b20-099a841bb83a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  2% 3/195 [00:05<06:04,  1.90s/it]\u001b[A\n",
            "  2% 4/195 [00:06<04:41,  1.47s/it]\u001b[A\n",
            "  3% 5/195 [00:08<05:00,  1.58s/it]\u001b[A\n",
            "  3% 6/195 [00:09<04:10,  1.32s/it]\u001b[A\n",
            "  4% 7/195 [00:10<04:04,  1.30s/it]\u001b[A\n",
            "  4% 8/195 [00:11<03:34,  1.15s/it]\u001b[A\n",
            "  5% 9/195 [00:12<03:21,  1.08s/it]\u001b[A\n",
            "  5% 10/195 [00:13<03:05,  1.00s/it]\u001b[A\n",
            "  6% 11/195 [00:14<03:22,  1.10s/it]\u001b[A\n",
            "  6% 12/195 [00:15<03:05,  1.01s/it]\u001b[A\n",
            "  7% 13/195 [00:16<03:13,  1.06s/it]\u001b[A\n",
            "  7% 14/195 [00:17<02:57,  1.02it/s]\u001b[A\n",
            "  8% 15/195 [00:18<03:20,  1.12s/it]\u001b[A\n",
            "  8% 16/195 [00:19<03:05,  1.03s/it]\u001b[A\n",
            "  9% 17/195 [00:22<04:32,  1.53s/it]\u001b[A\n",
            "  9% 18/195 [00:23<03:52,  1.32s/it]\u001b[A\n",
            " 10% 19/195 [00:24<03:59,  1.36s/it]\u001b[A\n",
            " 10% 20/195 [00:25<03:28,  1.19s/it]\u001b[A\n",
            " 11% 21/195 [00:26<03:27,  1.19s/it]\u001b[A\n",
            " 11% 22/195 [00:27<03:05,  1.07s/it]\u001b[A\n",
            " 12% 23/195 [00:28<03:20,  1.16s/it]\u001b[A\n",
            " 12% 24/195 [00:29<03:01,  1.06s/it]\u001b[A\n",
            " 13% 25/195 [00:30<03:12,  1.13s/it]\u001b[A\n",
            " 13% 26/195 [00:31<02:55,  1.04s/it]\u001b[A\n",
            " 14% 27/195 [00:32<02:59,  1.07s/it]\u001b[A\n",
            " 14% 28/195 [00:33<02:48,  1.01s/it]\u001b[A\n",
            " 15% 29/195 [00:35<03:42,  1.34s/it]\u001b[A\n",
            " 15% 30/195 [00:36<03:15,  1.18s/it]\u001b[A\n",
            " 16% 31/195 [00:38<04:06,  1.50s/it]\u001b[A\n",
            " 16% 32/195 [00:39<03:31,  1.30s/it]\u001b[A\n",
            " 17% 33/195 [00:40<03:21,  1.24s/it]\u001b[A\n",
            " 17% 34/195 [00:41<02:57,  1.10s/it]\u001b[A\n",
            " 18% 35/195 [00:42<03:12,  1.20s/it]\u001b[A\n",
            " 18% 36/195 [00:43<02:53,  1.09s/it]\u001b[A\n",
            " 19% 37/195 [00:44<02:52,  1.09s/it]\u001b[A\n",
            " 19% 38/195 [00:45<02:37,  1.00s/it]\u001b[A\n",
            " 20% 39/195 [00:47<02:53,  1.11s/it]\u001b[A\n",
            " 21% 40/195 [00:47<02:38,  1.02s/it]\u001b[A\n",
            " 21% 41/195 [00:49<03:12,  1.25s/it]\u001b[A\n",
            " 22% 42/195 [00:50<02:54,  1.14s/it]\u001b[A\n",
            " 22% 43/195 [00:52<03:52,  1.53s/it]\u001b[A\n",
            " 23% 44/195 [00:53<03:18,  1.32s/it]\u001b[A\n",
            " 23% 45/195 [00:55<03:24,  1.36s/it]\u001b[A\n",
            " 24% 46/195 [00:56<02:57,  1.19s/it]\u001b[A\n",
            " 24% 47/195 [00:57<03:04,  1.25s/it]\u001b[A\n",
            " 25% 48/195 [00:58<02:43,  1.11s/it]\u001b[A\n",
            " 25% 49/195 [00:59<02:46,  1.14s/it]\u001b[A\n",
            " 26% 50/195 [01:00<02:30,  1.04s/it]\u001b[A\n",
            " 26% 51/195 [01:01<02:41,  1.12s/it]\u001b[A\n",
            " 27% 52/195 [01:02<02:25,  1.02s/it]\u001b[A\n",
            " 27% 53/195 [01:03<02:27,  1.04s/it]\u001b[A\n",
            " 28% 54/195 [01:04<02:19,  1.01it/s]\u001b[A\n",
            " 28% 55/195 [01:06<03:11,  1.37s/it]\u001b[A\n",
            " 29% 56/195 [01:07<02:47,  1.20s/it]\u001b[A\n",
            " 29% 57/195 [01:10<02:51,  1.24s/it]\n",
            "  1% 6/1000 [24:36<67:55:29, 246.01s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/self-supervised/train.py\", line 60, in <module>\n",
            "    loss_ep.append(loss.item())\n",
            "KeyboardInterrupt\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 255).\u001b[0m Press Control-C to abort syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ep ▁▂▄▅▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss █▄▃▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ep 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss 0.65003\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msuper-monkey-5\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/naelm/self_supervised/runs/i7f9qtyk\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230427_023548-i7f9qtyk/logs\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python -m train --dataset cifar10 --epoch 1000 --lr 3e-3 --num_samples 4 --bs 256 --emb 64 --w_size 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDStJMwrt3Fn"
      },
      "source": [
        "# BYOL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Js8OeV9auUr4"
      },
      "outputs": [],
      "source": [
        "wandb.init(\n",
        "    project=\"BarlowTwin-v0-test\",\n",
        "    config={\n",
        "        \"max_epochs\": 10,\n",
        "        \"batch_size\": 256,\n",
        "        \"lr\": 0.06\n",
        "    })\n",
        "\n",
        "config = wandb.config\n",
        "\n",
        "\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "\n",
        "from lightly.data import LightlyDataset\n",
        "from lightly.data.multi_view_collate import MultiViewCollate\n",
        "from lightly.loss import NegativeCosineSimilarity\n",
        "from lightly.models.modules import BYOLPredictionHead, BYOLProjectionHead\n",
        "from lightly.models.utils import deactivate_requires_grad, update_momentum\n",
        "from lightly.transforms.simclr_transform import SimCLRTransform\n",
        "from lightly.utils.scheduler import cosine_schedule\n",
        "\n",
        "\n",
        "class BYOL(nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = backbone\n",
        "        self.projection_head = BYOLProjectionHead(512, 1024, 256)\n",
        "        self.prediction_head = BYOLPredictionHead(256, 1024, 256)\n",
        "\n",
        "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
        "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
        "\n",
        "        deactivate_requires_grad(self.backbone_momentum)\n",
        "        deactivate_requires_grad(self.projection_head_momentum)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(y)\n",
        "        p = self.prediction_head(z)\n",
        "        return p\n",
        "\n",
        "    def forward_momentum(self, x):\n",
        "        y = self.backbone_momentum(x).flatten(start_dim=1)\n",
        "        z = self.projection_head_momentum(y)\n",
        "        z = z.detach()\n",
        "        return z\n",
        "\n",
        "\n",
        "resnet = torchvision.models.resnet18()\n",
        "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "model = BYOL(backbone)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "cifar10 = torchvision.datasets.CIFAR10(\"datasets/cifar10\", download=True)\n",
        "transform = SimCLRTransform(input_size=32)\n",
        "dataset = LightlyDataset.from_torch_dataset(cifar10, transform=transform)\n",
        "# or create a dataset from a folder containing images or videos:\n",
        "# dataset = LightlyDataset(\"path/to/folder\")\n",
        "\n",
        "collate_fn = MultiViewCollate()\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=256,\n",
        "    collate_fn=collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=8,\n",
        ")\n",
        "\n",
        "criterion = NegativeCosineSimilarity()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.06)\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "print(\"Starting Training\")\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    momentum_val = cosine_schedule(epoch, epochs, 0.996, 1)\n",
        "    for (x0, x1), _, _ in dataloader:\n",
        "        update_momentum(model.backbone, model.backbone_momentum, m=momentum_val)\n",
        "        update_momentum(\n",
        "            model.projection_head, model.projection_head_momentum, m=momentum_val\n",
        "        )\n",
        "        x0 = x0.to(device)\n",
        "        x1 = x1.to(device)\n",
        "        p0 = model(x0)\n",
        "        z0 = model.forward_momentum(x0)\n",
        "        p1 = model(x1)\n",
        "        z1 = model.forward_momentum(x1)\n",
        "        loss = 0.5 * (criterion(p0, z1) + criterion(p1, z0))\n",
        "        total_loss += loss.detach()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62pZL_aRt8_M"
      },
      "source": [
        "# SimSiam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "No0KLizYuVMz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "\n",
        "from lightly.data import LightlyDataset\n",
        "from lightly.data.multi_view_collate import MultiViewCollate\n",
        "from lightly.loss import NegativeCosineSimilarity\n",
        "from lightly.models.modules import SimSiamPredictionHead, SimSiamProjectionHead\n",
        "from lightly.transforms import SimSiamTransform\n",
        "\n",
        "\n",
        "class SimSiam(nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.projection_head = SimSiamProjectionHead(512, 512, 128)\n",
        "        self.prediction_head = SimSiamPredictionHead(128, 64, 128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        f = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(f)\n",
        "        p = self.prediction_head(z)\n",
        "        z = z.detach()\n",
        "        return z, p\n",
        "\n",
        "\n",
        "resnet = torchvision.models.resnet18()\n",
        "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "model = SimSiam(backbone)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "cifar10 = torchvision.datasets.CIFAR10(\"datasets/cifar10\", download=True)\n",
        "transform = SimSiamTransform(input_size=32)\n",
        "dataset = LightlyDataset.from_torch_dataset(cifar10, transform=transform)\n",
        "\n",
        "collate_fn = MultiViewCollate()\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=256,\n",
        "    collate_fn=collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=8,\n",
        ")\n",
        "\n",
        "criterion = NegativeCosineSimilarity()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.06)\n",
        "\n",
        "print(\"Starting Training\")\n",
        "for epoch in range(10):\n",
        "    total_loss = 0\n",
        "    for (x0, x1), _, _ in dataloader:\n",
        "        x0 = x0.to(device)\n",
        "        x1 = x1.to(device)\n",
        "        z0, p0 = model(x0)\n",
        "        z1, p1 = model(x1)\n",
        "        loss = 0.5 * (criterion(z0, p1) + criterion(z1, p0))\n",
        "        total_loss += loss.detach()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Accuracy of the models \n",
        "\n"
      ],
      "metadata": {
        "id": "xdFO2LQrZZiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cazpuY5Zl6f",
        "outputId": "fbb24e50-4d74-4fe7-8df8-4b5a45a61e4f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.65.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.8.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.5.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.11.4)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.4.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.27.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.25.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.12)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Benchmark Results\n",
        "\n",
        "Updated: 27.03.2023 (42a6a924b1b6d5b6cc89a6b2a0a0942cc4af93ab)\n",
        "\n",
        "------------------------------------------------------------------------------------------\n",
        "| Model         | Batch Size | Epochs |  KNN Test Accuracy |       Time | Peak GPU Usage |\n",
        "------------------------------------------------------------------------------------------\n",
        "| BarlowTwins   |        128 |    200 |              0.842 |  375.9 Min |      1.7 GByte |\n",
        "| BYOL          |        128 |    200 |              0.869 |  121.9 Min |      1.6 GByte |\n",
        "| DCL           |        128 |    200 |              0.844 |  102.2 Min |      1.5 GByte |\n",
        "| DCLW          |        128 |    200 |              0.833 |  100.4 Min |      1.5 GByte |\n",
        "| DINO          |        128 |    200 |              0.840 |  120.3 Min |      1.6 GByte |\n",
        "| FastSiam      |        128 |    200 |              0.906 |  164.0 Min |      2.7 GByte |\n",
        "| Moco          |        128 |    200 |              0.838 |  128.8 Min |      1.7 GByte |\n",
        "| NNCLR         |        128 |    200 |              0.834 |  101.5 Min |      1.5 GByte |\n",
        "| SimCLR        |        128 |    200 |              0.847 |   97.7 Min |      1.5 GByte |\n",
        "| SimSiam       |        128 |    200 |              0.819 |   97.3 Min |      1.6 GByte |\n",
        "| SwaV          |        128 |    200 |              0.812 |   99.6 Min |      1.5 GByte |\n",
        "| SMoG          |        128 |    200 |              0.743 |  192.2 Min |      1.2 GByte |\n",
        "------------------------------------------------------------------------------------------\n",
        "| BarlowTwins   |        512 |    200 |              0.819 |  153.3 Min |      5.1 GByte |\n",
        "| BYOL          |        512 |    200 |              0.868 |  108.3 Min |      5.6 GByte |\n",
        "| DCL           |        512 |    200 |              0.840 |   88.2 Min |      4.9 GByte |\n",
        "| DCLW          |        512 |    200 |              0.824 |   87.9 Min |      4.9 GByte |\n",
        "| DINO          |        512 |    200 |              0.813 |  108.6 Min |      5.0 GByte |\n",
        "| FastSiam      |        512 |    200 |              0.788 |  146.9 Min |      9.5 GByte |\n",
        "| Moco (*)      |        512 |    200 |              0.847 |  112.2 Min |      5.6 GByte |\n",
        "| NNCLR (*)     |        512 |    200 |              0.815 |   88.1 Min |      5.0 GByte |\n",
        "| SimCLR        |        512 |    200 |              0.848 |   87.1 Min |      4.9 GByte |\n",
        "| SimSiam       |        512 |    200 |              0.764 |   87.8 Min |      5.0 GByte |\n",
        "| SwaV          |        512 |    200 |              0.842 |   88.7 Min |      4.9 GByte |\n",
        "| SMoG          |        512 |    200 |              0.686 |  110.0 Min |      3.4 GByte |\n",
        "------------------------------------------------------------------------------------------\n",
        "| BarlowTwins   |        512 |    800 |              0.859 |  517.5 Min |      7.9 GByte |\n",
        "| BYOL          |        512 |    800 |              0.910 |  400.9 Min |      5.4 GByte |\n",
        "| DCL           |        512 |    800 |              0.874 |  334.6 Min |      4.9 GByte |\n",
        "| DCLW          |        512 |    800 |              0.871 |  333.3 Min |      4.9 GByte |\n",
        "| DINO          |        512 |    800 |              0.848 |  405.2 Min |      5.0 GByte |\n",
        "| FastSiam      |        512 |    800 |              0.902 |  582.0 Min |      9.5 GByte |\n",
        "| Moco (*)      |        512 |    800 |              0.899 |  417.8 Min |      5.4 GByte |\n",
        "| NNCLR (*)     |        512 |    800 |              0.892 |  335.0 Min |      5.0 GByte |\n",
        "| SimCLR        |        512 |    800 |              0.879 |  331.1 Min |      4.9 GByte |\n",
        "| SimSiam       |        512 |    800 |              0.904 |  333.7 Min |      5.1 GByte |\n",
        "| SwaV          |        512 |    800 |              0.884 |  330.5 Min |      5.0 GByte |\n",
        "| SMoG          |        512 |    800 |              0.800 |  415.6 Min |      3.2 GByte |\n",
        "------------------------------------------------------------------------------------------\n",
        "\n",
        "(*): Increased size of memory bank from 4096 to 8192 to avoid too quickly \n",
        "changing memory bank due to larger batch size.\n",
        "\n",
        "The benchmarks were created on a single NVIDIA RTX A6000.\n",
        "\n",
        "Note that this benchmark also supports a multi-GPU setup. If you run it on\n",
        "a system with multiple GPUs make sure that you kill all the processes when\n",
        "killing the application. Due to the way we setup this benchmark the distributed\n",
        "processes might continue the benchmark if one of the nodes is killed.\n",
        "If you know how to fix this don't hesitate to create an issue or PR :)\n",
        "\n",
        "\"\"\"\n",
        "import copy\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pl_bolts.optimizers.lars import LARS\n",
        "\n",
        "from lightly.data import LightlyDataset\n",
        "from lightly.data.multi_view_collate import MultiViewCollate\n",
        "from lightly.loss import (\n",
        "    BarlowTwinsLoss,\n",
        "    DCLLoss,\n",
        "    DCLWLoss,\n",
        "    DINOLoss,\n",
        "    NegativeCosineSimilarity,\n",
        "    NTXentLoss,\n",
        "    SwaVLoss,\n",
        "    VICRegLLoss,\n",
        "    VICRegLoss,\n",
        "    memory_bank,\n",
        ")\n",
        "from lightly.models import ResNetGenerator, modules, utils\n",
        "from lightly.models.modules import heads\n",
        "from lightly.transforms import (\n",
        "    DINOTransform,\n",
        "    FastSiamTransform,\n",
        "    SimCLRTransform,\n",
        "    SimSiamTransform,\n",
        "    SMoGTransform,\n",
        "    SwaVTransform,\n",
        "    VICRegLTransform,\n",
        "    VICRegTransform,\n",
        ")\n",
        "from lightly.transforms.utils import IMAGENET_NORMALIZE\n",
        "from lightly.utils import scheduler\n",
        "from lightly.utils.benchmarking import BenchmarkModule\n",
        "\n",
        "logs_root_dir = os.path.join(os.getcwd(), \"benchmark_logs\")\n",
        "\n",
        "# set max_epochs to 800 for long run (takes around 10h on a single V100)\n",
        "max_epochs = 200\n",
        "num_workers = 8\n",
        "knn_k = 200\n",
        "knn_t = 0.1\n",
        "classes = 10\n",
        "\n",
        "# Set to True to enable Distributed Data Parallel training.\n",
        "distributed = False\n",
        "\n",
        "# Set to True to enable Synchronized Batch Norm (requires distributed=True).\n",
        "# If enabled the batch norm is calculated over all gpus, otherwise the batch\n",
        "# norm is only calculated from samples on the same gpu.\n",
        "sync_batchnorm = False\n",
        "\n",
        "# Set to True to gather features from all gpus before calculating\n",
        "# the loss (requires distributed=True).\n",
        "# If enabled then the loss on every gpu is calculated with features from all\n",
        "# gpus, otherwise only features from the same gpu are used.\n",
        "gather_distributed = False\n",
        "\n",
        "# benchmark\n",
        "n_runs = 1  # optional, increase to create multiple runs and report mean + std\n",
        "batch_size = 128\n",
        "lr_factor = batch_size / 128  # scales the learning rate linearly with batch size\n",
        "\n",
        "# Number of devices and hardware to use for training.\n",
        "devices = torch.cuda.device_count() if torch.cuda.is_available() else 1\n",
        "accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "if distributed:\n",
        "    strategy = \"ddp\"\n",
        "    # reduce batch size for distributed training\n",
        "    batch_size = batch_size // devices\n",
        "else:\n",
        "    strategy = None  # Set to \"auto\" if using PyTorch Lightning >= 2.0\n",
        "    # limit to single device if not using distributed training\n",
        "    devices = min(devices, 1)\n",
        "\n",
        "# Adapted from our MoCo Tutorial on CIFAR-10\n",
        "#\n",
        "# Replace the path with the location of your CIFAR-10 dataset.\n",
        "# We assume we have a train folder with subfolders\n",
        "# for each class and .png images inside.\n",
        "#\n",
        "# You can download `CIFAR-10 in folders from kaggle\n",
        "# <https://www.kaggle.com/swaroopkml/cifar10-pngs-in-folders>`_.\n",
        "\n",
        "# The dataset structure should be like this:\n",
        "# cifar10/train/\n",
        "#  L airplane/\n",
        "#    L 10008_airplane.png\n",
        "#    L ...\n",
        "#  L automobile/\n",
        "#  L bird/\n",
        "#  L cat/\n",
        "#  L deer/\n",
        "#  L dog/\n",
        "#  L frog/\n",
        "#  L horse/\n",
        "#  L ship/\n",
        "#  L truck/\n",
        "path_to_train = \"/datasets/cifar10/train/\"\n",
        "path_to_test = \"/datasets/cifar10/test/\"\n",
        "\n",
        "# Collate function init\n",
        "collate_fn = MultiViewCollate()\n",
        "\n",
        "# Use SimCLR augmentations\n",
        "simclr_transform = SimCLRTransform(\n",
        "    input_size=32,\n",
        "    cj_strength=0.5,\n",
        "    gaussian_blur=0.0,\n",
        ")\n",
        "\n",
        "# Use SimSiam augmentations\n",
        "simsiam_transform = SimSiamTransform(\n",
        "    input_size=32,\n",
        "    gaussian_blur=0.0,\n",
        ")\n",
        "\n",
        "# Multi crop augmentation for FastSiam\n",
        "fast_siam_transform = FastSiamTransform(input_size=32, gaussian_blur=0.0)\n",
        "\n",
        "# Multi crop augmentation for SwAV, additionally, disable blur for cifar10\n",
        "swav_transform = SwaVTransform(\n",
        "    crop_sizes=[32],\n",
        "    crop_counts=[2],  # 2 crops @ 32x32px\n",
        "    crop_min_scales=[0.14],\n",
        "    cj_strength=0.5,\n",
        "    gaussian_blur=0,\n",
        ")\n",
        "\n",
        "# Multi crop augmentation for DINO, additionally, disable blur for cifar10\n",
        "dino_transform = DINOTransform(\n",
        "    global_crop_size=32,\n",
        "    n_local_views=0,\n",
        "    cj_strength=0.5,\n",
        "    gaussian_blur=(0, 0, 0),\n",
        ")\n",
        "\n",
        "# Two crops for SMoG\n",
        "smog_transform = SMoGTransform(\n",
        "    crop_sizes=(32, 32),\n",
        "    crop_counts=(1, 1),\n",
        "    cj_strength=0.5,\n",
        "    gaussian_blur_probs=(0.0, 0.0),\n",
        "    crop_min_scales=(0.2, 0.2),\n",
        "    crop_max_scales=(1.0, 1.0),\n",
        ")\n",
        "\n",
        "vicreg_transform = VICRegTransform(\n",
        "    input_size=32,\n",
        "    cj_strength=0.5,\n",
        ")\n",
        "# Transform  passing geometrical transformation for VICRegL\n",
        "vicregl_transform = VICRegLTransform(\n",
        "    global_crop_size=128,\n",
        "    n_local_views=0,\n",
        "    global_grid_size=4,\n",
        "    cj_strength=0.5,\n",
        ")\n",
        "\n",
        "# No additional augmentations for the test set\n",
        "test_transforms = torchvision.transforms.Compose(\n",
        "    [\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize(\n",
        "            mean=IMAGENET_NORMALIZE[\"mean\"],\n",
        "            std=IMAGENET_NORMALIZE[\"std\"],\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# we use test transformations for getting the feature for kNN on train data\n",
        "dataset_train_kNN = LightlyDataset(input_dir=path_to_train, transform=test_transforms)\n",
        "\n",
        "dataset_test = LightlyDataset(input_dir=path_to_test, transform=test_transforms)\n",
        "\n",
        "\n",
        "def create_dataset_train_ssl(model):\n",
        "    \"\"\"Helper method to apply the correct transform for ssl.\n",
        "\n",
        "    Args:\n",
        "        model:\n",
        "            Model class for which to select the transform.\n",
        "    \"\"\"\n",
        "    model_to_transform = {\n",
        "        BarlowTwinsModel: simclr_transform,\n",
        "        BYOLModel: simclr_transform,\n",
        "        DCL: simclr_transform,\n",
        "        DCLW: simclr_transform,\n",
        "        DINOModel: dino_transform,\n",
        "        FastSiamModel: fast_siam_transform,\n",
        "        MocoModel: simclr_transform,\n",
        "        NNCLRModel: simclr_transform,\n",
        "        SimCLRModel: simclr_transform,\n",
        "        SimSiamModel: simsiam_transform,\n",
        "        SwaVModel: swav_transform,\n",
        "        SMoGModel: smog_transform,\n",
        "        VICRegModel: vicreg_transform,\n",
        "        VICRegLModel: vicregl_transform,\n",
        "    }\n",
        "    transform = model_to_transform[model]\n",
        "    return LightlyDataset(input_dir=path_to_train, transform=transform)\n",
        "\n",
        "\n",
        "def get_data_loaders(batch_size: int, dataset_train_ssl):\n",
        "    \"\"\"Helper method to create dataloaders for ssl, kNN train and kNN test.\n",
        "\n",
        "    Args:\n",
        "        batch_size: Desired batch size for all dataloaders.\n",
        "    \"\"\"\n",
        "    dataloader_train_ssl = torch.utils.data.DataLoader(\n",
        "        dataset_train_ssl,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn,\n",
        "        drop_last=True,\n",
        "        num_workers=num_workers,\n",
        "    )\n",
        "\n",
        "    dataloader_train_kNN = torch.utils.data.DataLoader(\n",
        "        dataset_train_kNN,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        drop_last=False,\n",
        "        num_workers=num_workers,\n",
        "    )\n",
        "\n",
        "    dataloader_test = torch.utils.data.DataLoader(\n",
        "        dataset_test,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        drop_last=False,\n",
        "        num_workers=num_workers,\n",
        "    )\n",
        "\n",
        "    return dataloader_train_ssl, dataloader_train_kNN, dataloader_test\n",
        "\n",
        "\n",
        "class MocoModel(BenchmarkModule):\n",
        "    def __init__(self, dataloader_kNN, num_classes):\n",
        "        super().__init__(dataloader_kNN, num_classes)\n",
        "\n",
        "        # create a ResNet backbone and remove the classification head\n",
        "        num_splits = 0 if sync_batchnorm else 8\n",
        "        resnet = ResNetGenerator(\"resnet-18\", num_splits=num_splits)\n",
        "        self.backbone = nn.Sequential(\n",
        "            *list(resnet.children())[:-1], nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "\n",
        "        # create a moco model based on ResNet\n",
        "        self.projection_head = heads.MoCoProjectionHead(512, 512, 128)\n",
        "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
        "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
        "        utils.deactivate_requires_grad(self.backbone_momentum)\n",
        "        utils.deactivate_requires_grad(self.projection_head_momentum)\n",
        "\n",
        "        # create our loss with the optional memory bank\n",
        "        self.criterion = NTXentLoss(\n",
        "            temperature=0.1,\n",
        "            memory_bank_size=4096,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x).flatten(start_dim=1)\n",
        "        return self.projection_head(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        (x0, x1), _, _ = batch\n",
        "\n",
        "        # update momentum\n",
        "        utils.update_momentum(self.backbone, self.backbone_momentum, 0.99)\n",
        "        utils.update_momentum(self.projection_head, self.projection_head_momentum, 0.99)\n",
        "\n",
        "        def step(x0_, x1_):\n",
        "            x1_, shuffle = utils.batch_shuffle(x1_, distributed=distributed)\n",
        "            x0_ = self.backbone(x0_).flatten(start_dim=1)\n",
        "            x0_ = self.projection_head(x0_)\n",
        "\n",
        "            x1_ = self.backbone_momentum(x1_).flatten(start_dim=1)\n",
        "            x1_ = self.projection_head_momentum(x1_)\n",
        "            x1_ = utils.batch_unshuffle(x1_, shuffle, distributed=distributed)\n",
        "            return x0_, x1_\n",
        "\n",
        "        # We use a symmetric loss (model trains faster at little compute overhead)\n",
        "        # https://colab.research.google.com/github/facebookresearch/moco/blob/colab-notebook/colab/moco_cifar10_demo.ipynb\n",
        "        loss_1 = self.criterion(*step(x0, x1))\n",
        "        loss_2 = self.criterion(*step(x1, x0))\n",
        "\n",
        "        loss = 0.5 * (loss_1 + loss_2)\n",
        "        self.log(\"train_loss_ssl\", loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        params = list(self.backbone.parameters()) + list(\n",
        "            self.projection_head.parameters()\n",
        "        )\n",
        "        optim = torch.optim.SGD(\n",
        "            params,\n",
        "            lr=6e-2 * lr_factor,\n",
        "            momentum=0.9,\n",
        "            weight_decay=5e-4,\n",
        "        )\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
        "        return [optim], [scheduler]\n",
        "\n",
        "\n",
        "class SimCLRModel(BenchmarkModule):\n",
        "    def __init__(self, dataloader_kNN, num_classes):\n",
        "        super().__init__(dataloader_kNN, num_classes)\n",
        "        # create a ResNet backbone and remove the classification head\n",
        "        resnet = ResNetGenerator(\"resnet-18\")\n",
        "        self.backbone = nn.Sequential(\n",
        "            *list(resnet.children())[:-1], nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "        self.projection_head = heads.SimCLRProjectionHead(512, 512, 128)\n",
        "        self.criterion = NTXentLoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(x)\n",
        "        return z\n",
        "\n",
        "    def training_step(self, batch, batch_index):\n",
        "        (x0, x1), _, _ = batch\n",
        "        z0 = self.forward(x0)\n",
        "        z1 = self.forward(x1)\n",
        "        loss = self.criterion(z0, z1)\n",
        "        self.log(\"train_loss_ssl\", loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optim = torch.optim.SGD(\n",
        "            self.parameters(), lr=6e-2 * lr_factor, momentum=0.9, weight_decay=5e-4\n",
        "        )\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
        "        return [optim], [scheduler]\n",
        "\n",
        "\n",
        "class SimSiamModel(BenchmarkModule):\n",
        "    def __init__(self, dataloader_kNN, num_classes):\n",
        "        super().__init__(dataloader_kNN, num_classes)\n",
        "        # create a ResNet backbone and remove the classification head\n",
        "        resnet = ResNetGenerator(\"resnet-18\")\n",
        "        self.backbone = nn.Sequential(\n",
        "            *list(resnet.children())[:-1], nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "        self.prediction_head = heads.SimSiamPredictionHead(2048, 512, 2048)\n",
        "        # use a 2-layer projection head for cifar10 as described in the paper\n",
        "        self.projection_head = heads.ProjectionHead(\n",
        "            [\n",
        "                (512, 2048, nn.BatchNorm1d(2048), nn.ReLU(inplace=True)),\n",
        "                (2048, 2048, nn.BatchNorm1d(2048), None),\n",
        "            ]\n",
        "        )\n",
        "        self.criterion = NegativeCosineSimilarity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        f = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(f)\n",
        "        p = self.prediction_head(z)\n",
        "        z = z.detach()\n",
        "        return z, p\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        (x0, x1), _, _ = batch\n",
        "        z0, p0 = self.forward(x0)\n",
        "        z1, p1 = self.forward(x1)\n",
        "        loss = 0.5 * (self.criterion(z0, p1) + self.criterion(z1, p0))\n",
        "        self.log(\"train_loss_ssl\", loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optim = torch.optim.SGD(\n",
        "            self.parameters(),\n",
        "            lr=6e-2,  # no lr-scaling, results in better training stability\n",
        "            momentum=0.9,\n",
        "            weight_decay=5e-4,\n",
        "        )\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
        "        return [optim], [scheduler]\n",
        "\n",
        "\n",
        "class FastSiamModel(SimSiamModel):\n",
        "    def __init__(self, dataloader_kNN, num_classes):\n",
        "        super().__init__(dataloader_kNN, num_classes)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        views, _, _ = batch\n",
        "        features = [self.forward(view) for view in views]\n",
        "        zs = torch.stack([z for z, _ in features])\n",
        "        ps = torch.stack([p for _, p in features])\n",
        "\n",
        "        loss = 0.0\n",
        "        for i in range(len(views)):\n",
        "            mask = torch.arange(len(views), device=self.device) != i\n",
        "            loss += self.criterion(ps[i], torch.mean(zs[mask], dim=0)) / len(views)\n",
        "\n",
        "        self.log(\"train_loss_ssl\", loss)\n",
        "        return loss\n",
        "\n",
        "\n",
        "class BarlowTwinsModel(BenchmarkModule):\n",
        "    def __init__(self, dataloader_kNN, num_classes):\n",
        "        super().__init__(dataloader_kNN, num_classes)\n",
        "        # create a ResNet backbone and remove the classification head\n",
        "        resnet = ResNetGenerator(\"resnet-18\")\n",
        "        self.backbone = nn.Sequential(\n",
        "            *list(resnet.children())[:-1], nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "        # use a 2-layer projection head for cifar10 as described in the paper\n",
        "        self.projection_head = heads.ProjectionHead(\n",
        "            [\n",
        "                (512, 2048, nn.BatchNorm1d(2048), nn.ReLU(inplace=True)),\n",
        "                (2048, 2048, None, None),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.criterion = BarlowTwinsLoss(gather_distributed=gather_distributed)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(x)\n",
        "        return z\n",
        "\n",
        "    def training_step(self, batch, batch_index):\n",
        "        (x0, x1), _, _ = batch\n",
        "        z0 = self.forward(x0)\n",
        "        z1 = self.forward(x1)\n",
        "        loss = self.criterion(z0, z1)\n",
        "        self.log(\"train_loss_ssl\", loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optim = torch.optim.SGD(\n",
        "            self.parameters(), lr=6e-2 * lr_factor, momentum=0.9, weight_decay=5e-4\n",
        "        )\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
        "        return [optim], [scheduler]\n",
        "\n",
        "\n",
        "class BYOLModel(BenchmarkModule):\n",
        "    def __init__(self, dataloader_kNN, num_classes):\n",
        "        super().__init__(dataloader_kNN, num_classes)\n",
        "        # create a ResNet backbone and remove the classification head\n",
        "        resnet = ResNetGenerator(\"resnet-18\")\n",
        "        self.backbone = nn.Sequential(\n",
        "            *list(resnet.children())[:-1], nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "\n",
        "        # create a byol model based on ResNet\n",
        "        self.projection_head = heads.BYOLProjectionHead(512, 1024, 256)\n",
        "        self.prediction_head = heads.BYOLPredictionHead(256, 1024, 256)\n",
        "\n",
        "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
        "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
        "\n",
        "        utils.deactivate_requires_grad(self.backbone_momentum)\n",
        "        utils.deactivate_requires_grad(self.projection_head_momentum)\n",
        "\n",
        "        self.criterion = NegativeCosineSimilarity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(y)\n",
        "        p = self.prediction_head(z)\n",
        "        return p\n",
        "\n",
        "    def forward_momentum(self, x):\n",
        "        y = self.backbone_momentum(x).flatten(start_dim=1)\n",
        "        z = self.projection_head_momentum(y)\n",
        "        z = z.detach()\n",
        "        return z\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        utils.update_momentum(self.backbone, self.backbone_momentum, m=0.99)\n",
        "        utils.update_momentum(\n",
        "            self.projection_head, self.projection_head_momentum, m=0.99\n",
        "        )\n",
        "        (x0, x1), _, _ = batch\n",
        "        p0 = self.forward(x0)\n",
        "        z0 = self.forward_momentum(x0)\n",
        "        p1 = self.forward(x1)\n",
        "        z1 = self.forward_momentum(x1)\n",
        "        loss = 0.5 * (self.criterion(p0, z1) + self.criterion(p1, z0))\n",
        "        self.log(\"train_loss_ssl\", loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        params = (\n",
        "            list(self.backbone.parameters())\n",
        "            + list(self.projection_head.parameters())\n",
        "            + list(self.prediction_head.parameters())\n",
        "        )\n",
        "        optim = torch.optim.SGD(\n",
        "            params,\n",
        "            lr=6e-2 * lr_factor,\n",
        "            momentum=0.9,\n",
        "            weight_decay=5e-4,\n",
        "        )\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
        "        return [optim], [scheduler]\n",
        "\n",
        "\n",
        "class VICRegModel(BenchmarkModule):\n",
        "    def __init__(self, dataloader_kNN, num_classes):\n",
        "        super().__init__(dataloader_kNN, num_classes)\n",
        "        # create a ResNet backbone and remove the classification head\n",
        "        resnet = torchvision.models.resnet18()\n",
        "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "        self.projection_head = heads.BarlowTwinsProjectionHead(512, 2048, 2048)\n",
        "        self.criterion = VICRegLoss()\n",
        "        self.warmup_epochs = 40 if max_epochs >= 800 else 20\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(x)\n",
        "        return z\n",
        "\n",
        "    def training_step(self, batch, batch_index):\n",
        "        (x0, x1), _, _ = batch\n",
        "        z0 = self.forward(x0)\n",
        "        z1 = self.forward(x1)\n",
        "        loss = self.criterion(z0, z1)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Training diverges without LARS\n",
        "        optim = LARS(\n",
        "            self.parameters(),\n",
        "            lr=0.3 * lr_factor,\n",
        "            weight_decay=1e-4,\n",
        "            momentum=0.9,\n",
        "        )\n",
        "        cosine_scheduler = scheduler.CosineWarmupScheduler(\n",
        "            optim, self.warmup_epochs, max_epochs\n",
        "        )\n",
        "        return [optim], [cosine_scheduler]\n",
        "\n",
        "\n",
        "class VICRegLModel(BenchmarkModule):\n",
        "    def __init__(self, dataloader_kNN, num_classes):\n",
        "        super().__init__(dataloader_kNN, num_classes)\n",
        "        # create a ResNet backbone and remove the classification head\n",
        "        resnet = torchvision.models.resnet18()\n",
        "\n",
        "        # The train_backbone variable is introduced in order to fit with the\n",
        "        # structure of BenchmarkModule. During training, train_backbone is used\n",
        "        # to extract local and global features. Durig evaluation, backbone is used\n",
        "        # to evaluate global features.\n",
        "        self.train_backbone = nn.Sequential(*list(resnet.children())[:-2])\n",
        "        self.projection_head = heads.BarlowTwinsProjectionHead(512, 2048, 2048)\n",
        "        self.local_projection_head = heads.VicRegLLocalProjectionHead(512, 128, 128)\n",
        "        self.average_pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "        self.criterion = VICRegLLoss(num_matches=(16, 4))\n",
        "        self.backbone = nn.Sequential(self.train_backbone, self.average_pool)\n",
        "        self.warmup_epochs = 20 if max_epochs >= 800 else 10\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.train_backbone(x)\n",
        "        y = self.average_pool(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(y)\n",
        "        y_local = x.permute(0, 2, 3, 1)  # (B, D, H, W) to (B, H, W, D)\n",
        "        z_local = self.local_projection_head(y_local)\n",
        "        return z, z_local\n",
        "\n",
        "    def training_step(self, batch, batch_index):\n",
        "        views_and_grids = batch[0]\n",
        "        views = views_and_grids[: len(views_and_grids) // 2]\n",
        "        grids = views_and_grids[len(views_and_grids) // 2 :]\n",
        "        features = [self.forward(view) for view in views]\n",
        "        loss = self.criterion(\n",
        "            global_view_features=features[:2],\n",
        "            global_view_grids=grids[:2],\n",
        "            local_view_features=features[2:],\n",
        "            local_view_grids=grids[2:],\n",
        "        )\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Training diverges without LARS\n",
        "        optim = LARS(\n",
        "            self.parameters(),\n",
        "            lr=0.3 * lr_factor,\n",
        "            weight_decay=1e-4,\n",
        "            momentum=0.9,\n",
        "        )\n",
        "        cosine_scheduler = scheduler.CosineWarmupScheduler(\n",
        "            optim, self.warmup_epochs, max_epochs\n",
        "        )\n",
        "        return [optim], [cosine_scheduler]\n",
        "\n",
        "\n",
        "# class SwaVModel(BenchmarkModule):\n",
        "#     def __init__(self, dataloader_kNN, num_classes):\n",
        "#         super().__init__(dataloader_kNN, num_classes)\n",
        "#         # create a ResNet backbone and remove the classification head\n",
        "#         resnet = ResNetGenerator(\"resnet-18\")\n",
        "#         self.backbone = nn.Sequential(\n",
        "#             *list(resnet.children())[:-1], nn.AdaptiveAvgPool2d(1)\n",
        "#         )\n",
        "\n",
        "#         self.projection_head = heads.SwaVProjectionHead(512, 512, 128)\n",
        "#         self.prototypes = heads.SwaVPrototypes(128, 512)  # use 512 prototypes\n",
        "\n",
        "#         self.criterion = SwaVLoss(sinkhorn_gather_distributed=gather_distributed)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.backbone(x).flatten(start_dim=1)\n",
        "#         x = self.projection_head(x)\n",
        "#         x = nn.functional.normalize(x, dim=1, p=2)\n",
        "#         return self.prototypes(x)\n",
        "\n",
        "#     def training_step(self, batch, batch_idx):\n",
        "#         # normalize the prototypes so they are on the unit sphere\n",
        "#         self.prototypes.normalize()\n",
        "\n",
        "#         # the multi-crop dataloader returns a list of image crops where the\n",
        "#         # first two items are the high resolution crops and the rest are low\n",
        "#         # resolution crops\n",
        "#         multi_crops, _, _ = batch\n",
        "#         multi_crop_features = [self.forward(x) for x in multi_crops]\n",
        "\n",
        "#         # split list of crop features into high and low resolution\n",
        "#         high_resolution_features = multi_crop_features[:2]\n",
        "#         low_resolution_features = multi_crop_features[2:]\n",
        "\n",
        "#         # calculate the SwaV loss\n",
        "#         loss = self.criterion(high_resolution_features, low_resolution_features)\n",
        "\n",
        "#         self.log(\"train_loss_ssl\", loss)\n",
        "#         return loss\n",
        "\n",
        "#     def configure_optimizers(self):\n",
        "#         optim = torch.optim.Adam(\n",
        "#             self.parameters(),\n",
        "#             lr=1e-3 * lr_factor,\n",
        "#             weight_decay=1e-6,\n",
        "#         )\n",
        "#         scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
        "#         return [optim], [scheduler]\n",
        "\n",
        "\n",
        "class NNCLRModel(BenchmarkModule):\n",
        "    def __init__(self, dataloader_kNN, num_classes):\n",
        "        super().__init__(dataloader_kNN, num_classes)\n",
        "        # create a ResNet backbone and remove the classification head\n",
        "        resnet = ResNetGenerator(\"resnet-18\")\n",
        "        self.backbone = nn.Sequential(\n",
        "            *list(resnet.children())[:-1], nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "        self.prediction_head = heads.NNCLRPredictionHead(256, 4096, 256)\n",
        "        # use only a 2-layer projection head for cifar10\n",
        "        self.projection_head = heads.ProjectionHead(\n",
        "            [\n",
        "                (512, 2048, nn.BatchNorm1d(2048), nn.ReLU(inplace=True)),\n",
        "                (2048, 256, nn.BatchNorm1d(256), None),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.criterion = NTXentLoss()\n",
        "        self.memory_bank = modules.NNMemoryBankModule(size=4096)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(y)\n",
        "        p = self.prediction_head(z)\n",
        "        z = z.detach()\n",
        "        return z, p\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        (x0, x1), _, _ = batch\n",
        "        z0, p0 = self.forward(x0)\n",
        "        z1, p1 = self.forward(x1)\n",
        "        z0 = self.memory_bank(z0, update=False)\n",
        "        z1 = self.memory_bank(z1, update=True)\n",
        "        loss = 0.5 * (self.criterion(z0, p1) + self.criterion(z1, p0))\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optim = torch.optim.SGD(\n",
        "            self.parameters(),\n",
        "            lr=6e-2 * lr_factor,\n",
        "            momentum=0.9,\n",
        "            weight_decay=5e-4,\n",
        "        )\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
        "        return [optim], [scheduler]\n",
        "\n",
        "\n",
        "class DINOModel(BenchmarkModule):\n",
        "    def __init__(self, dataloader_kNN, num_classes):\n",
        "        super().__init__(dataloader_kNN, num_classes)\n",
        "        # create a ResNet backbone and remove the classification head\n",
        "        resnet = ResNetGenerator(\"resnet-18\")\n",
        "        self.backbone = nn.Sequential(\n",
        "            *list(resnet.children())[:-1], nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "        self.head = self._build_projection_head()\n",
        "        self.teacher_backbone = copy.deepcopy(self.backbone)\n",
        "        self.teacher_head = self._build_projection_head()\n",
        "\n",
        "        utils.deactivate_requires_grad(self.teacher_backbone)\n",
        "        utils.deactivate_requires_grad(self.teacher_head)\n",
        "\n",
        "        self.criterion = DINOLoss(output_dim=2048)\n",
        "\n",
        "    def _build_projection_head(self):\n",
        "        head = heads.DINOProjectionHead(512, 2048, 256, 2048, batch_norm=True)\n",
        "        # use only 2 layers for cifar10\n",
        "        head.layers = heads.ProjectionHead(\n",
        "            [\n",
        "                (512, 2048, nn.BatchNorm1d(2048), nn.GELU()),\n",
        "                (2048, 256, None, None),\n",
        "            ]\n",
        "        ).layers\n",
        "        return head\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.head(y)\n",
        "        return z\n",
        "\n",
        "    def forward_teacher(self, x):\n",
        "        y = self.teacher_backbone(x).flatten(start_dim=1)\n",
        "        z = self.teacher_head(y)\n",
        "        return z\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        utils.update_momentum(self.backbone, self.teacher_backbone, m=0.99)\n",
        "        utils.update_momentum(self.head, self.teacher_head, m=0.99)\n",
        "        views, _, _ = batch\n",
        "        views = [view.to(self.device) for view in views]\n",
        "        global_views = views[:2]\n",
        "        teacher_out = [self.forward_teacher(view) for view in global_views]\n",
        "        student_out = [self.forward(view) for view in views]\n",
        "        loss = self.criterion(teacher_out, student_out, epoch=self.current_epoch)\n",
        "        self.log(\"train_loss_ssl\", loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        param = list(self.backbone.parameters()) + list(self.head.parameters())\n",
        "        optim = torch.optim.SGD(\n",
        "            param,\n",
        "            lr=6e-2 * lr_factor,\n",
        "            momentum=0.9,\n",
        "            weight_decay=5e-4,\n",
        "        )\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
        "        return [optim], [scheduler]\n",
        "\n",
        "\n",
        "class DCL(BenchmarkModule):\n",
        "    def __init__(self, dataloader_kNN, num_classes):\n",
        "        super().__init__(dataloader_kNN, num_classes)\n",
        "        # create a ResNet backbone and remove the classification head\n",
        "        resnet = ResNetGenerator(\"resnet-18\")\n",
        "        self.backbone = nn.Sequential(\n",
        "            *list(resnet.children())[:-1], nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "        self.projection_head = heads.SimCLRProjectionHead(512, 512, 128)\n",
        "        self.criterion = DCLLoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(x)\n",
        "        return z\n",
        "\n",
        "    def training_step(self, batch, batch_index):\n",
        "        (x0, x1), _, _ = batch\n",
        "        z0 = self.forward(x0)\n",
        "        z1 = self.forward(x1)\n",
        "        loss = self.criterion(z0, z1)\n",
        "        self.log(\"train_loss_ssl\", loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optim = torch.optim.SGD(\n",
        "            self.parameters(), lr=6e-2 * lr_factor, momentum=0.9, weight_decay=5e-4\n",
        "        )\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
        "        return [optim], [scheduler]\n",
        "\n",
        "\n",
        "class DCLW(BenchmarkModule):\n",
        "    def __init__(self, dataloader_kNN, num_classes):\n",
        "        super().__init__(dataloader_kNN, num_classes)\n",
        "        # create a ResNet backbone and remove the classification head\n",
        "        resnet = ResNetGenerator(\"resnet-18\")\n",
        "        self.backbone = nn.Sequential(\n",
        "            *list(resnet.children())[:-1], nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "        self.projection_head = heads.SimCLRProjectionHead(512, 512, 128)\n",
        "        self.criterion = DCLWLoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(x)\n",
        "        return z\n",
        "\n",
        "    def training_step(self, batch, batch_index):\n",
        "        (x0, x1), _, _ = batch\n",
        "        z0 = self.forward(x0)\n",
        "        z1 = self.forward(x1)\n",
        "        loss = self.criterion(z0, z1)\n",
        "        self.log(\"train_loss_ssl\", loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optim = torch.optim.SGD(\n",
        "            self.parameters(), lr=6e-2 * lr_factor, momentum=0.9, weight_decay=5e-4\n",
        "        )\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
        "        return [optim], [scheduler]\n",
        "\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "class SMoGModel(BenchmarkModule):\n",
        "    def __init__(self, dataloader_kNN, num_classes):\n",
        "        super().__init__(dataloader_kNN, num_classes)\n",
        "\n",
        "        # create a ResNet backbone and remove the classification head\n",
        "        resnet = ResNetGenerator(\"resnet-18\")\n",
        "        self.backbone = nn.Sequential(\n",
        "            *list(resnet.children())[:-1], nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "\n",
        "        # create a model based on ResNet\n",
        "        self.projection_head = heads.SMoGProjectionHead(512, 2048, 128)\n",
        "        self.prediction_head = heads.SMoGPredictionHead(128, 2048, 128)\n",
        "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
        "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
        "        utils.deactivate_requires_grad(self.backbone_momentum)\n",
        "        utils.deactivate_requires_grad(self.projection_head_momentum)\n",
        "\n",
        "        # smog\n",
        "        self.n_groups = 300\n",
        "        memory_bank_size = 10000\n",
        "        self.memory_bank = memory_bank.MemoryBankModule(size=memory_bank_size)\n",
        "        # create our loss\n",
        "        group_features = torch.nn.functional.normalize(\n",
        "            torch.rand(self.n_groups, 128), dim=1\n",
        "        )\n",
        "        self.smog = heads.SMoGPrototypes(group_features=group_features, beta=0.99)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def _cluster_features(self, features: torch.Tensor) -> torch.Tensor:\n",
        "        features = features.cpu().numpy()\n",
        "        kmeans = KMeans(self.n_groups).fit(features)\n",
        "        clustered = torch.from_numpy(kmeans.cluster_centers_).float()\n",
        "        clustered = torch.nn.functional.normalize(clustered, dim=1)\n",
        "        return clustered\n",
        "\n",
        "    def _reset_group_features(self):\n",
        "        # see https://arxiv.org/pdf/2207.06167.pdf Table 7b)\n",
        "        features = self.memory_bank.bank\n",
        "        group_features = self._cluster_features(features.t())\n",
        "        self.smog.set_group_features(group_features)\n",
        "\n",
        "    def _reset_momentum_weights(self):\n",
        "        # see https://arxiv.org/pdf/2207.06167.pdf Table 7b)\n",
        "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
        "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
        "        utils.deactivate_requires_grad(self.backbone_momentum)\n",
        "        utils.deactivate_requires_grad(self.projection_head_momentum)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        if self.global_step > 0 and self.global_step % 300 == 0:\n",
        "            # reset group features and weights every 300 iterations\n",
        "            self._reset_group_features()\n",
        "            self._reset_momentum_weights()\n",
        "        else:\n",
        "            # update momentum\n",
        "            utils.update_momentum(self.backbone, self.backbone_momentum, 0.99)\n",
        "            utils.update_momentum(\n",
        "                self.projection_head, self.projection_head_momentum, 0.99\n",
        "            )\n",
        "\n",
        "        (x0, x1), _, _ = batch\n",
        "\n",
        "        if batch_idx % 2:\n",
        "            # swap batches every second iteration\n",
        "            x0, x1 = x1, x0\n",
        "\n",
        "        x0_features = self.backbone(x0).flatten(start_dim=1)\n",
        "        x0_encoded = self.projection_head(x0_features)\n",
        "        x0_predicted = self.prediction_head(x0_encoded)\n",
        "        x1_features = self.backbone_momentum(x1).flatten(start_dim=1)\n",
        "        x1_encoded = self.projection_head_momentum(x1_features)\n",
        "\n",
        "        # update group features and get group assignments\n",
        "        assignments = self.smog.assign_groups(x1_encoded)\n",
        "        group_features = self.smog.get_updated_group_features(x0_encoded)\n",
        "        logits = self.smog(x0_predicted, group_features, temperature=0.1)\n",
        "        self.smog.set_group_features(group_features)\n",
        "\n",
        "        loss = self.criterion(logits, assignments)\n",
        "\n",
        "        # use memory bank to periodically reset the group features with k-means\n",
        "        self.memory_bank(x0_encoded, update=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        params = (\n",
        "            list(self.backbone.parameters())\n",
        "            + list(self.projection_head.parameters())\n",
        "            + list(self.prediction_head.parameters())\n",
        "        )\n",
        "        optim = torch.optim.SGD(\n",
        "            params,\n",
        "            lr=0.01,\n",
        "            momentum=0.9,\n",
        "            weight_decay=1e-6,\n",
        "        )\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
        "        return [optim], [scheduler]\n",
        "\n",
        "\n",
        "models = [\n",
        "    BarlowTwinsModel,\n",
        "    BYOLModel,\n",
        "    SimSiamModel,\n",
        "    VICRegModel,\n",
        "]\n",
        "bench_results = dict()\n",
        "\n",
        "experiment_version = None\n",
        "# loop through configurations and train models\n",
        "for BenchmarkModel in models:\n",
        "    runs = []\n",
        "    model_name = BenchmarkModel.__name__.replace(\"Model\", \"\")\n",
        "    for seed in range(n_runs):\n",
        "        pl.seed_everything(seed)\n",
        "        dataset_train_ssl = create_dataset_train_ssl(BenchmarkModel)\n",
        "        dataloader_train_ssl, dataloader_train_kNN, dataloader_test = get_data_loaders(\n",
        "            batch_size=batch_size, dataset_train_ssl=dataset_train_ssl\n",
        "        )\n",
        "        benchmark_model = BenchmarkModel(dataloader_train_kNN, classes)\n",
        "\n",
        "        # Save logs to: {CWD}/benchmark_logs/cifar10/{experiment_version}/{model_name}/\n",
        "        # If multiple runs are specified a subdirectory for each run is created.\n",
        "        sub_dir = model_name if n_runs <= 1 else f\"{model_name}/run{seed}\"\n",
        "        logger = TensorBoardLogger(\n",
        "            save_dir=os.path.join(logs_root_dir, \"cifar10\"),\n",
        "            name=\"\",\n",
        "            sub_dir=sub_dir,\n",
        "            version=experiment_version,\n",
        "        )\n",
        "        if experiment_version is None:\n",
        "            # Save results of all models under same version directory\n",
        "            experiment_version = logger.version\n",
        "        checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "            dirpath=os.path.join(logger.log_dir, \"checkpoints\")\n",
        "        )\n",
        "        trainer = pl.Trainer(\n",
        "            max_epochs=max_epochs,\n",
        "            devices=devices,\n",
        "            accelerator=accelerator,\n",
        "            default_root_dir=logs_root_dir,\n",
        "            strategy=strategy,\n",
        "            sync_batchnorm=sync_batchnorm,\n",
        "            logger=logger,\n",
        "            callbacks=[checkpoint_callback],\n",
        "        )\n",
        "        start = time.time()\n",
        "        trainer.fit(\n",
        "            benchmark_model,\n",
        "            train_dataloaders=dataloader_train_ssl,\n",
        "            val_dataloaders=dataloader_test,\n",
        "        )\n",
        "        end = time.time()\n",
        "        run = {\n",
        "            \"model\": model_name,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"epochs\": max_epochs,\n",
        "            \"max_accuracy\": benchmark_model.max_accuracy,\n",
        "            \"runtime\": end - start,\n",
        "            \"gpu_memory_usage\": torch.cuda.max_memory_allocated(),\n",
        "            \"seed\": seed,\n",
        "        }\n",
        "        runs.append(run)\n",
        "        print(run)\n",
        "\n",
        "        # delete model and trainer + free up cuda memory\n",
        "        del benchmark_model\n",
        "        del trainer\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    bench_results[model_name] = runs\n",
        "\n",
        "# print results table\n",
        "header = (\n",
        "    f\"| {'Model':<13} | {'Batch Size':>10} | {'Epochs':>6} \"\n",
        "    f\"| {'KNN Test Accuracy':>18} | {'Time':>10} | {'Peak GPU Usage':>14} |\"\n",
        ")\n",
        "print(\"-\" * len(header))\n",
        "print(header)\n",
        "print(\"-\" * len(header))\n",
        "for model, results in bench_results.items():\n",
        "    runtime = np.array([result[\"runtime\"] for result in results])\n",
        "    runtime = runtime.mean() / 60  # convert to min\n",
        "    accuracy = np.array([result[\"max_accuracy\"] for result in results])\n",
        "    gpu_memory_usage = np.array([result[\"gpu_memory_usage\"] for result in results])\n",
        "    gpu_memory_usage = gpu_memory_usage.max() / (1024**3)  # convert to gbyte\n",
        "\n",
        "    if len(accuracy) > 1:\n",
        "        accuracy_msg = f\"{accuracy.mean():>8.3f} +- {accuracy.std():>4.3f}\"\n",
        "    else:\n",
        "        accuracy_msg = f\"{accuracy.mean():>18.3f}\"\n",
        "\n",
        "    print(\n",
        "        f\"| {model:<13} | {batch_size:>10} | {max_epochs:>6} \"\n",
        "        f\"| {accuracy_msg} | {runtime:>6.1f} Min \"\n",
        "        f\"| {gpu_memory_usage:>8.1f} GByte |\",\n",
        "        flush=True,\n",
        "    )\n",
        "print(\"-\" * len(header))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "3ryABMy5Zhh3",
        "outputId": "23a45ee5-1184-440f-d3ad-b5e71416fee7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-0a406b7cb09d>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorBoardLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlars\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLARS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlightly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLightlyDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pl_bolts/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0m_HTTPS_AWS_HUB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://pl-bolts-weights.s3.us-east-2.amazonaws.com\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m from pl_bolts import (  # noqa: E402\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdatamodules\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pl_bolts/callbacks/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"Collection of PyTorchLightning callbacks.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyol_updates\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBYOLMAWeightUpdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_monitor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModuleDataMonitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingDataMonitor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPrintTableMetricsCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparseml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparseMLCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pl_bolts/callbacks/data_monitor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLightningModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLightningLoggerBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorBoardLogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWandbLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrank_zero_warn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_func\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapply_to_collection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'LightningLoggerBase' from 'pytorch_lightning.loggers' (/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loggers/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "n1U2KmIuuMJ_",
        "bbezgE5MmPlW"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1caf21ab99984e9bb0321d9c240b57d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24babb3fa24140ad9810682be73e3faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3f1536fbecb4f818efa5a4bd272fcab",
            "placeholder": "​",
            "style": "IPY_MODEL_c5116606ca3b42ea97dea84f2bb29a0d",
            "value": "Epoch 7:  18%"
          }
        },
        "688f650350a440a390fa8dcec3b04905": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24babb3fa24140ad9810682be73e3faf",
              "IPY_MODEL_fbf93f2532da4fbb97be9d1fa24625f2",
              "IPY_MODEL_fb1b1e5e7bed478fbaf0170be55f2928"
            ],
            "layout": "IPY_MODEL_bdeeadf648084ae197d5111479d81239"
          }
        },
        "7c1ac5a015e043f499fba391cda8b5d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad62ad3b64fc473db567f104498d5ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdeeadf648084ae197d5111479d81239": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "c5116606ca3b42ea97dea84f2bb29a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf503d517c7f46c98966ea2d1746479f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3f1536fbecb4f818efa5a4bd272fcab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb1b1e5e7bed478fbaf0170be55f2928": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c1ac5a015e043f499fba391cda8b5d7",
            "placeholder": "​",
            "style": "IPY_MODEL_ad62ad3b64fc473db567f104498d5ad7",
            "value": " 35/195 [04:25&lt;20:14,  7.59s/it, v_num=0]"
          }
        },
        "fbf93f2532da4fbb97be9d1fa24625f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf503d517c7f46c98966ea2d1746479f",
            "max": 195,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1caf21ab99984e9bb0321d9c240b57d7",
            "value": 35
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}